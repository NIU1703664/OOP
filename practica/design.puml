@startuml
skinparam classAttributeIconSize 0
skinparam noteFontSize 11

abstract class Impurity {
  {abstract}+ purity(dataset: Dataset): float
}

class Gini {
  + purity(dataset: Dataset): float
}

class Entropy {
  + purity(dataset: Dataset): float
}

class SSE {
  + purity(dataset: Dataset): float
}

abstract class Split {
  - criterion: Impurity
  {abstract}+ _best_split(features: int[], dataset: Dataset): tuple[int, float, float, list[Dataset]]
  + _CART_cost(left: Dataset, right: Dataset): float
}

class RandomSplit {
  + _best_split(features: int[], dataset: Dataset): tuple[int, float, float, list[Dataset]]
}

class ExtraSplit {
  + _best_split(features: int[], dataset: Dataset): tuple[int, float, float, list[Dataset]]
}

class Dataset {
  - X: float[][]
  - y: int[] | float[]
  - num_samples: int
  - num_features: int
  
  + random_sampling(ratio: float): Dataset
  + most_frequent_label(): int
  + label_average(): float
  + split(feature: int, value: float): tuple[Dataset, Dataset]
  + load_sonar(): Dataset {static}
  + load_iris(): Dataset {static}
  + load_MNIST(): Dataset {static}
  + load_temperatures(): Dataset {static}
}

abstract class Node {
  {abstract}+ predict(row: float[]): int | float
  {abstract}+ accept(visitor: NodeVisitor)
}

class Leaf {
  - label: int | float
  + predict(row: float[]): int | float
  + accept(visitor: NodeVisitor)
}

class Parent {
  - feature_index: int
  - threshold: float
  - left_child: Node
  - right_child: Node
  + predict(row: float[]): int | float
  + accept(visitor: NodeVisitor)
}

abstract class NodeVisitor {
  {abstract}+ visitLeaf(node: Leaf)
  {abstract}+ visitParent(node: Parent)
}

class PrintNode {
  - depth: int
  + visitLeaf(node: Leaf)
  + visitParent(node: Parent)
}

class FeatureImportance {
  - occurences: dict[int, int]
  + visitLeaf(node: Leaf)
  + visitParent(node: Parent)
}

abstract class Forest {
  - num_trees: int
  - min_size: int
  - max_depth: int
  - ratio_samples: float
  - num_random_features: int
  - split: Split
  - parallel: bool
  - time: float
  - decision_trees: list<Node>
  
  + fit(X: float[][], y: int[] | float[]): void
  {abstract}+ predict(X: float[][]): int[] | float[]
  + print_trees(): void
  + feature_importance(): dict[int, int]
  # _make_node(dataset: Dataset, depth: int): Node
  {abstract}# _make_leaf(dataset: Dataset): Leaf
  # _make_parent_or_leaf(dataset: Dataset, depth: int): Node
  # _make_decision_trees(dataset: Dataset)
  # _make_decision_trees_multiprocessing(dataset: Dataset)
}

class Classifier {
  + _make_leaf(dataset: Dataset): Leaf
  + predict(X: float[][]): int[]
}

class Regressor {
  + _make_leaf(dataset: Dataset): Leaf
  + predict(X: float[][]): float[]
}

Impurity <|-- Gini
Impurity <|-- Entropy
Impurity <|-- SSE
Forest <|-- Classifier
Forest <|-- Regressor
Forest *-right-> Node : decision_trees
Forest --> Split : split strategy
Forest -left-> Dataset : uses
Node <|-- Leaf
Node <|-- Parent
Parent *-left-> Node
Parent *-right-> Node
Split o-left-> Impurity : criterion
Split <|-- RandomSplit
Split <|-- ExtraSplit
NodeVisitor <|-- PrintNode
NodeVisitor <|-- FeatureImportance
Leaf ..> NodeVisitor : accepts
Parent ..> NodeVisitor : accepts
@enduml

